{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac763eab-99da-4f8b-8d74-e9518a8bfb42",
   "metadata": {
    "id": "ac763eab-99da-4f8b-8d74-e9518a8bfb42"
   },
   "source": [
    "#Â Mammalian Cortical Surface Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CneQjHZvI3Xl",
   "metadata": {
    "id": "CneQjHZvI3Xl"
   },
   "source": [
    "Cortical Surface reconstruction from an MRI image is a very involved task, we will make it only slightly easier by providing you with the segmentation, which you will need to reconstruct the surface. In this notebook you will learn to work with this 3D data, learn to reconstruct surfaces from a segmentation, and extract measurements for comparative studies.\n",
    "\n",
    "We will however also show that the segmentation itself is often not sufficient for accurate reconstructions due to the high degree of folding. We instead propose a novel method which relies on first reconstructing the White Matter surface, and the displacing it to the Pial surface.\n",
    "\n",
    "But no worries, we will get you through it..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seWI-5SxI33V",
   "metadata": {
    "id": "seWI-5SxI33V"
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EOJ6dMhYNnwp",
   "metadata": {
    "id": "EOJ6dMhYNnwp"
   },
   "source": [
    "Here we first download the modules we require for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cS9gb2cYJsLk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cS9gb2cYJsLk",
    "outputId": "f0d4441e-a8d4-423d-f487-bde448bbe006"
   },
   "outputs": [],
   "source": [
    "! pip install nibabel trimesh scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "not2Me_4LtyW",
   "metadata": {
    "id": "not2Me_4LtyW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import trimesh\n",
    "import scipy\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rMzNniBPI35u",
   "metadata": {
    "id": "rMzNniBPI35u"
   },
   "source": [
    "And then download the data we need from our repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ruXzVtVJ-_Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ruXzVtVJ-_Z",
    "outputId": "7910d32f-9430-4e9d-d3cb-01215e9f23b4"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/TimoBl/CorticalSegmentationRepository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UT0K8gg9SZw2",
   "metadata": {
    "id": "UT0K8gg9SZw2"
   },
   "source": [
    "## Working with Segmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mjcaDxZkSe3u",
   "metadata": {
    "id": "mjcaDxZkSe3u"
   },
   "source": [
    "MRI images are acquired in a DICOM format, which are actually only stacks of 2D images oriented in a certain space. The scientific (imaging) community has largely shifted to Nifti images due to their simplicity. Each image is represent as a 3D array of numbers, and an affine matrix which tells us the orientation, position and resolution in the scanner space. More information about this on the [Nibabel website](https://nipy.org/nibabel/coordinate_systems.html). So we will load the pre-processed segmentation of one of our specimens, the sealion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PeilPmKCSeTA",
   "metadata": {
    "id": "PeilPmKCSeTA"
   },
   "outputs": [],
   "source": [
    "species = \"out_sealion\"\n",
    "\n",
    "file = nib.load(\"/content/CorticalSegmentationRepository/\" + species + \"/seg.nii.gz\")\n",
    "img, affine = file.get_fdata().astype(int), file.affine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JeV-iV3eU-0m",
   "metadata": {
    "id": "JeV-iV3eU-0m"
   },
   "source": [
    "We can view the 3D image by slicing it with an index, on any of the three axis (axial, sagittal, coronal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-JJJFFW-Sdp2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "-JJJFFW-Sdp2",
    "outputId": "6a16b959-feba-4bf1-d488-733a9a6ec4d4"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img[:, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MzPJUDk0WAkE",
   "metadata": {
    "id": "MzPJUDk0WAkE"
   },
   "source": [
    "Normally, each voxel in the image will have any float value, but in a segmentation image each voxel will have a discrete categorical variable assigned. In our case, 0 will represent the background, 3 the white matter, 2 the grey matter. So we can access each class individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PL0o8b9ON2st",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "PL0o8b9ON2st",
    "outputId": "58e872f3-b0ab-4835-9815-a4006b103972"
   },
   "outputs": [],
   "source": [
    "plt.imshow((img == 2)[:, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eLRGkF54a54r",
   "metadata": {
    "id": "eLRGkF54a54r"
   },
   "source": [
    "Now we could for example count the number of voxel to get our volume measurements. The problem is each voxel will have a volume which is dependent on the resolution of the original image. Happily we can extract this information from the header, which give the size in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U7qkg6vmbCk4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U7qkg6vmbCk4",
    "outputId": "1b728566-ab13-4cf9-819c-a562b319a8d8"
   },
   "outputs": [],
   "source": [
    "pixdim = file.header[\"pixdim\"][1:4]\n",
    "pixdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L8OhQa4ibgUd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8OhQa4ibgUd",
    "outputId": "77b21506-78f9-4a6f-a3bd-4c2675eebbe7"
   },
   "outputs": [],
   "source": [
    "pixel_vol = np.prod(pixdim)\n",
    "pixel_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9xpMQlSObykL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xpMQlSObykL",
    "outputId": "1ecca6d3-ae4a-4052-9095-de0923e8b765"
   },
   "outputs": [],
   "source": [
    "gm_volume = (img == 2).sum() * pixel_vol\n",
    "gm_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JMpnmLhOcF7F",
   "metadata": {
    "id": "JMpnmLhOcF7F"
   },
   "source": [
    "So we have succesfully extracted the volume of the grey matter in mm!\n",
    "\n",
    "**Exercises:**\n",
    " * give the white matter volume and the whole brain volume in liters\n",
    " * give the number of voxels in each coronal slice, and find the index of the \"widest\" slice (or part) of the brain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BqCB3X9hakxr",
   "metadata": {
    "id": "BqCB3X9hakxr"
   },
   "source": [
    "## Reconstructing the Surface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wN8sHMJVawK-",
   "metadata": {
    "id": "wN8sHMJVawK-"
   },
   "source": [
    "Now we only have the volumetric measurements of the brain, but not the surface measurements. One of the most commonly used algorithm to go from the voxel space to a polygonal mesh is the marching cubes algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XA_zWFl8euuK",
   "metadata": {
    "id": "XA_zWFl8euuK"
   },
   "outputs": [],
   "source": [
    "mask = (img > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I9b0yc6Yavda",
   "metadata": {
    "id": "I9b0yc6Yavda"
   },
   "outputs": [],
   "source": [
    "vert, fcs, _, val = skimage.measure.marching_cubes(1 - mask, allow_degenerate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-WFE_K6kP2sR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WFE_K6kP2sR",
    "outputId": "3b43983c-e862-4d3c-a4a4-98eac41c2cbd"
   },
   "outputs": [],
   "source": [
    "vert, fcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pwNr0UAIPqRj",
   "metadata": {
    "id": "pwNr0UAIPqRj"
   },
   "source": [
    "A mesh is composed of vertices, which have a certain position in space, and faces, which describes how these faces are connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1LxlVauKanLn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "1LxlVauKanLn",
    "outputId": "7669afe8-f501-4d55-b220-a4210344df3c"
   },
   "outputs": [],
   "source": [
    "pial_srf = trimesh.base.Trimesh(vertices=vert, faces=fcs)\n",
    "pial_srf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qhJLvT7JjQ0e",
   "metadata": {
    "id": "qhJLvT7JjQ0e"
   },
   "source": [
    "And we already have the pial surface! But you will see that it's heavily jagged, so we will use smoothing. Different methods with different settings can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P-HKHL6SjanP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "P-HKHL6SjanP",
    "outputId": "46f2356d-8892-4f8b-b2d1-dc05f62799c4"
   },
   "outputs": [],
   "source": [
    "pial_srf = trimesh.smoothing.filter_humphrey(pial_srf)\n",
    "pial_srf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Gr4pMPtbkOp7",
   "metadata": {
    "id": "Gr4pMPtbkOp7"
   },
   "source": [
    "You will observe that the surfaces might include some artefacts, or holes. The [trimesh library](https://trimesh.org/trimesh.repair.html) has a number of functions to deal with this. However, we also have to be aware that most of these artefacts come from the segmentation itself, which is by nature not perfect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H6YP8s5xZmnA",
   "metadata": {
    "id": "H6YP8s5xZmnA"
   },
   "source": [
    "**Exercises**\n",
    "* Try to improve the segmentation (suggestions: full connectivity and flood filling)\n",
    "* Find ways to remove artefacts from the surface mesh itself\n",
    "* Marching cubes algorithms can also use information about the heigth, meaning that each voxel has also a scalar information about where the surface actually is. We suggest experimenting with chamber distance transforms (scipy.ndimage.\n",
    "distance_transform_cdt), to give as an additionall level input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OQQgrmdHlz49",
   "metadata": {
    "id": "OQQgrmdHlz49"
   },
   "source": [
    "## Displacing the surface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3KHbmOKl8_z",
   "metadata": {
    "id": "b3KHbmOKl8_z"
   },
   "source": [
    "Even when improving the pial surfaces, they look slightly melted and tend to miss a lot of informations. However, something interesting happens when we look at the white matter surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HvzX60uund_8",
   "metadata": {
    "id": "HvzX60uund_8"
   },
   "outputs": [],
   "source": [
    "mask = (img == 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rKAT1ej-l19j",
   "metadata": {
    "id": "rKAT1ej-l19j"
   },
   "outputs": [],
   "source": [
    "vert, fcs, _, val = skimage.measure.marching_cubes(1 - mask, allow_degenerate=False)\n",
    "white_srf = trimesh.base.Trimesh(vertices=vert, faces=fcs)\n",
    "white_srf = trimesh.smoothing.filter_humphrey(white_srf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OHA_eUDsl1_5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "OHA_eUDsl1_5",
    "outputId": "882e041f-dfce-403d-8f8f-c30eeddc8b8c"
   },
   "outputs": [],
   "source": [
    "white_srf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14HaNhb0nuoz",
   "metadata": {
    "id": "14HaNhb0nuoz"
   },
   "source": [
    "The surface looks astoundingly good, especially the sulcis which tend to be extremly well preserved. The reason is that in the pial surface, voxels from opposing walls will be labeled as grey matter with no outside voxel in between, meaning they will just fuse together. We are inherently limited by the resolution of the original scan. In the white matter however, there will be grey matter sitting above it, separating the sulci and opening it up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8CWSjJY-pP9J",
   "metadata": {
    "id": "8CWSjJY-pP9J"
   },
   "source": [
    "Our fundammental assumption we will make from now, is that we can find a correspondance between the white matter surface and the pial surface. This is a problem which has already been addressed in cortical thickness measurements. We will rely on the DiReCT method [https://doi.org/10.1016/j.neuroimage.2008.12.016](https://doi.org/10.1016/j.neuroimage.2008.12.016), a diffeomorphic displacement method which will try to morph the white matter segmentation into the grey matter segmentation, through the use of velocity field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VEMPB3Vorj7U",
   "metadata": {
    "id": "VEMPB3Vorj7U"
   },
   "source": [
    "We won't go into the details of the method here, but in summary it produces a 3D velocity field, with 10 different timepoints. The method can take around 30 minutes to run, so we pre-processed the examples for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CCh9g2OLrjW9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCh9g2OLrjW9",
    "outputId": "5a72e3d8-e1b8-4a99-cfb4-c8741d5200be"
   },
   "outputs": [],
   "source": [
    "vel = nib.load(\"/content/CorticalSegmentationRepository/\" + species + \"/ForwardVelocityField.nii.gz\").get_fdata()\n",
    "vel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k4cLzWPMkIaZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "k4cLzWPMkIaZ",
    "outputId": "298c1362-55dc-40bb-f2a7-d0267b7b7ade"
   },
   "outputs": [],
   "source": [
    "T = 9 # timepoints\n",
    "c = 0 # x,y,z components of vectors\n",
    "plt.imshow(vel[:, 50, :, T, c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5vGPfn_0sUtd",
   "metadata": {
    "id": "5vGPfn_0sUtd"
   },
   "source": [
    "Now we want to displace our points from the white matter mesh to the pial surface using this velocity field. Each point in the mesh will be interpolate through the velocity and time, and moved. Several interpolation methods can be used, but we will use a simple, discrete and efficient method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RziU7a0ijapv",
   "metadata": {
    "id": "RziU7a0ijapv"
   },
   "outputs": [],
   "source": [
    "# DiReCT deformation Field\n",
    "def apply_deformation(points, def_field, step_size=0.1, order=1):\n",
    "\n",
    "    for i in range(0, 10, 1):\n",
    "        vx = def_field[ :, :, :, i, 0]\n",
    "        vy = def_field[ :, :, :, i, 1]\n",
    "        vz = def_field[ :, :, :, i, 2]\n",
    "\n",
    "        for j in np.arange(0, 1, step_size):\n",
    "            v = np.array([\n",
    "                scipy.ndimage.map_coordinates(vx, points.T, order=order),\n",
    "                scipy.ndimage.map_coordinates(vy, points.T, order=order),\n",
    "                scipy.ndimage.map_coordinates(vz, points.T, order=order)\n",
    "            ]).T\n",
    "\n",
    "            points += (step_size * v)\n",
    "\n",
    "        print(i, end=\", \", flush=True)\n",
    "\n",
    "    print(\"Finished\", flush=True)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cACWOgtzN2vS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cACWOgtzN2vS",
    "outputId": "44be47b8-11a9-408d-acab-94a8b4944f91"
   },
   "outputs": [],
   "source": [
    "new_vertices = apply_deformation(white_srf.vertices.copy(), vel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aYa4nN0dtpWB",
   "metadata": {
    "id": "aYa4nN0dtpWB"
   },
   "source": [
    "We then insert our new vertices into the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A2FbLtvktZnp",
   "metadata": {
    "id": "A2FbLtvktZnp"
   },
   "outputs": [],
   "source": [
    "pial_srf = trimesh.base.Trimesh(vertices=new_vertices, faces=white_srf.faces)\n",
    "pial_srf = trimesh.smoothing.filter_humphrey(pial_srf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u4NGbLe5N2xj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "u4NGbLe5N2xj",
    "outputId": "a6d1ca1e-0a4f-41fa-a9c9-bf55766fd156"
   },
   "outputs": [],
   "source": [
    "pial_srf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "izyQt-L_tvma",
   "metadata": {
    "id": "izyQt-L_tvma"
   },
   "source": [
    "Tadaaaaa! The surface looks just very good! Many of artefacts we had previously just disappeared, and the sulcii are much better preserved. We sometimes have small spikes, but they won't influence our measurements much. One surface we are still missing is the exposed area. Also here, there are different ways to estimate it. For simplicity, we can use the convex hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xyN3kWkI8hcA",
   "metadata": {
    "id": "xyN3kWkI8hcA"
   },
   "outputs": [],
   "source": [
    "exp_srf = trimesh.convex.convex_hull(pial_srf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WjrAatP_9Q46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "WjrAatP_9Q46",
    "outputId": "d1c1b7ae-71eb-4244-c9f1-2a74542ac0a7"
   },
   "outputs": [],
   "source": [
    "exp_srf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CpNR8s3V9a2c",
   "metadata": {
    "id": "CpNR8s3V9a2c"
   },
   "source": [
    "However, the convex hull will bridge the thalamic structures and is more sensitive to artefacts. Therefore, we suggest implementing a different method, like the [rollling ball method](https://en.wikipedia.org/wiki/Rolling_ball_argument), which is also a better geometrical argument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ogaL98RgZjXh",
   "metadata": {
    "id": "ogaL98RgZjXh"
   },
   "source": [
    "**Exercise**\n",
    "* Add your improved surface reconstruction method for the white matter, before displacing it to the pial\n",
    "* Implement the rolling ball method for extracting the exposed area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92o9DbJvw24X",
   "metadata": {
    "id": "92o9DbJvw24X"
   },
   "source": [
    "## Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_Jn-73k3vhRZ",
   "metadata": {
    "id": "_Jn-73k3vhRZ"
   },
   "source": [
    "So we can now extract our measurements from the surfaces. The problem is however that alike the volume, the measurement are in the voxel space, and not in the scanner space (which is in mm). So we have to register the mesh back to this space. We will provide you with the affine transformation code, to avoid sleepless nights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UBotmhJEvfHR",
   "metadata": {
    "id": "UBotmhJEvfHR"
   },
   "outputs": [],
   "source": [
    "def get_vox2ras_tkr(t1):\n",
    "    ds = t1.header._structarr['pixdim'][1:4]\n",
    "    ns = t1.header._structarr['dim'][1:4] * ds / 2.0\n",
    "    v2rtkr = np.array([[-ds[0], 0, 0, ns[0]],\n",
    "                       [0, 0, ds[2], -ns[2]],\n",
    "                       [0, -ds[1], 0, ns[1]],\n",
    "                       [0, 0, 0, 1]], dtype=np.float32)\n",
    "    return v2rtkr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "klzd_lyyvlcm",
   "metadata": {
    "id": "klzd_lyyvlcm"
   },
   "outputs": [],
   "source": [
    "def register(mesh, ref_volume):\n",
    "\n",
    "    # we transform mesh\n",
    "    affine = get_vox2ras_tkr(ref_volume)\n",
    "\n",
    "    # apply affine for FS visualization and matching with the MRI\n",
    "    mesh.vertices = nib.affines.apply_affine(affine, mesh.vertices)\n",
    "    mesh.invert()\n",
    "\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xocy24qXv4Kh",
   "metadata": {
    "id": "xocy24qXv4Kh"
   },
   "outputs": [],
   "source": [
    "white_srf = register(white_srf, file)\n",
    "pial_srf = register(pial_srf, file)\n",
    "exp_srf = register(exp_srf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k9K92TUx0Zlw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9K92TUx0Zlw",
    "outputId": "919b432f-a06c-4cc4-d007-8a0031ba9bae"
   },
   "outputs": [],
   "source": [
    "white_srf.area, pial_srf.area, exp_srf.area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3hJnT5iwzGs",
   "metadata": {
    "id": "g3hJnT5iwzGs"
   },
   "source": [
    "The surfaces are now correctly registered, and we can use their measurements. We can also estimate cortical thickness by dividing the grey matter volume by the surface area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-JoSQNJpwt8D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-JoSQNJpwt8D",
    "outputId": "6c42d177-3ddd-4bff-cb96-4df6d09968e0"
   },
   "outputs": [],
   "source": [
    "thickness = gm_volume / pial_srf.area\n",
    "thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RuCRqKBjz7AJ",
   "metadata": {
    "id": "RuCRqKBjz7AJ"
   },
   "source": [
    "For thickness, there is actually a better way to estimate it. All our points move from the white matter surface to the pial surface through a diffeomorphism, meaning paths are curved but noninteresecting\n",
    "\n",
    "**Exercise**\n",
    "* Implement the curvilinear cortical thickness measure (be carefull of the scale here as well!)\n",
    "* Peform point-wise study of thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IHBBBX_e-Uz-",
   "metadata": {
    "id": "IHBBBX_e-Uz-"
   },
   "source": [
    "## Group Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "my3ZlE89-kfD",
   "metadata": {
    "id": "my3ZlE89-kfD"
   },
   "source": [
    "Now we have all the elements we need for a group study. Additionnaly to the sealion, we provide you with two seals *(out_seal4, out_seal5)*, two raccoons *(out_raccoon, out_raccoon_2)*, a human *(out_human)*, a bear *(out_bear4)* and harbour porpoise *(out_HP1)*. We suggest you group all your improved code into a function which takes care of reconstructing the different surfaces and extracting the measurements. We simply provide you with the baseline /content/results.csv data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nJJtfAAYZOrB",
   "metadata": {
    "id": "nJJtfAAYZOrB"
   },
   "source": [
    "**Exercise**\n",
    "* Group measurements with your new method\n",
    "* Calculate the gyrification index, and the new variables of brain morphometry (I, K, S)\n",
    "* Derive the scaling law\n",
    "* Get local measurements of gyrification (pro-level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nu3zad9kaNsY",
   "metadata": {
    "id": "nu3zad9kaNsY"
   },
   "source": [
    "$$GI=\\frac{A_t}{A_e}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JyhI3P92TPuI",
   "metadata": {
    "id": "JyhI3P92TPuI"
   },
   "source": [
    "$$K = \\log A_t + \\frac{1}{4} \\log T^2 - \\frac{5}{4} \\log A_e$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LXHNRfvQTX8P",
   "metadata": {
    "id": "LXHNRfvQTX8P"
   },
   "source": [
    "$$I = \\log A_t + \\log T^2 + \\log A_e$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SJlvbV7fTakf",
   "metadata": {
    "id": "SJlvbV7fTakf"
   },
   "source": [
    "$$S = \\frac{2}{3} \\log A_t - \\frac{9}{4} \\log T^2 + \\frac{4}{3} \\log A_e$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGo6FwMNALMj",
   "metadata": {
    "id": "RGo6FwMNALMj"
   },
   "source": [
    "*This Tutorial was made by Timo Blattner and Bruno Mota*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DeepScan",
   "language": "python",
   "name": "deepscan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
